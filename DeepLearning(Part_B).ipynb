{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNyZ-zZxlU6G"
      },
      "source": [
        "# Neural Networks with PyTorch\n",
        "\n",
        "In this assignment, we are going to train a Neural Networks on the Japanese MNIST dataset. It is composed of 70000 images of handwritten Hiragana characters. The target variables has 10 different classes.\n",
        "\n",
        "Each image is of dimension 28 by 28. But we will flatten them to form a dataset composed of vectors of dimension (784, 1). The training process will be similar as for a structured dataset.\n",
        "\n",
        "<img src='https://drive.google.com/uc?id=16TqEl9ESfXYbUpVafXD6h5UpJYGKfMxE' width=\"500\" height=\"200\">\n",
        "\n",
        "Your goal is to run at least 3 experiments and get a model that can achieve 80% accuracy with not much overfitting on this dataset.\n",
        "\n",
        "Some of the code have already been defined for you. You need only to add your code in the sections specified (marked with **TODO**). Some assert statements have been added to verify the expected outputs are correct. If it does throw an error, this means your implementation is behaving as expected.\n",
        "\n",
        "Note: You can only use fully-connected and dropout layers for this assignment. You can not convolution layers for instance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOufKqO8mw7n"
      },
      "source": [
        "# 1. Import Required Packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-sGJ26pmz4A"
      },
      "source": [
        "[1.1] We are going to use numpy, matplotlib and google.colab packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oTGG80etnMAa"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vyky0K3fnEFO"
      },
      "source": [
        "# 2. Download Dataset\n",
        "\n",
        "We will store the dataset into your personal Google Drive.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltUMtjG-nX-b"
      },
      "source": [
        "[2.1] Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N_FVrXICnMJM"
      },
      "outputs": [],
      "source": [
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzLtlKCHnT9H"
      },
      "source": [
        "[2.2] Create a folder called `DL_ASG_1` on your Google Drive at the root level"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XZicoPks4POW"
      },
      "outputs": [],
      "source": [
        "! mkdir -p /content/gdrive/MyDrive/DL_ASG_1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sToej_3CnePP"
      },
      "source": [
        "[2.3] Navigate to this folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g2oAXToKnpXj"
      },
      "outputs": [],
      "source": [
        "%cd '/content/gdrive/MyDrive/DL_ASG_1'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnRHIyhlzUwL"
      },
      "source": [
        "[2.4] Show the list of item on the folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y-xYtezBzQ0c"
      },
      "outputs": [],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vlfobqnnjJ1"
      },
      "source": [
        "[2.4] Dowload the dataset files to your Google Drive if required"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M0owzTC427NM"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from tqdm import tqdm\n",
        "import os.path\n",
        "\n",
        "def download_file(url):\n",
        "    path = url.split('/')[-1]\n",
        "    if os.path.isfile(path):\n",
        "        print (f\"{path} already exists\")\n",
        "    else:\n",
        "      r = requests.get(url, stream=True)\n",
        "      with open(path, 'wb') as f:\n",
        "          total_length = int(r.headers.get('content-length'))\n",
        "          print('Downloading {} - {:.1f} MB'.format(path, (total_length / 1024000)))\n",
        "          for chunk in tqdm(r.iter_content(chunk_size=1024), total=int(total_length / 1024) + 1, unit=\"KB\"):\n",
        "              if chunk:\n",
        "                  f.write(chunk)\n",
        "\n",
        "url_list = [\n",
        "    'http://codh.rois.ac.jp/kmnist/dataset/kmnist/kmnist-train-imgs.npz',\n",
        "    'http://codh.rois.ac.jp/kmnist/dataset/kmnist/kmnist-train-labels.npz',\n",
        "    'http://codh.rois.ac.jp/kmnist/dataset/kmnist/kmnist-test-imgs.npz',\n",
        "    'http://codh.rois.ac.jp/kmnist/dataset/kmnist/kmnist-test-labels.npz'\n",
        "]\n",
        "\n",
        "for url in url_list:\n",
        "    download_file(url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Z_1zKurN4H0"
      },
      "source": [
        "[2.5] List the content of the folder and confirm files have been dowloaded properly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vt6ZKf4fnqkq"
      },
      "outputs": [],
      "source": [
        "! ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvvfOON36hTf"
      },
      "source": [
        "# 3. Load Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "duFjgsyPoLPR"
      },
      "source": [
        "[3.1] Import the required modules from PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1zolHKEO7GZA"
      },
      "outputs": [],
      "source": [
        "# TODO (Students need to fill this section)\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4Aw5ObQoWdI"
      },
      "source": [
        "[3.2] **TODO** Create 2 variables called `img_height` and `img_width` that will both take the value 28"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ip0NFeyjpj79"
      },
      "outputs": [],
      "source": [
        "# TODO (Students need to fill this section)\n",
        "img_height = 28\n",
        "img_width = 28"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmX5SEHkpp63"
      },
      "source": [
        "[3.3] Create a function that loads a .npz file using numpy and return the content of the `arr_0` key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5S3cthx57L2f"
      },
      "outputs": [],
      "source": [
        "def load(f):\n",
        "    return np.load(f)['arr_0']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8V2Ij9s7qRtj"
      },
      "source": [
        "[3.4] **TODO** Load the 4 files saved on your Google Drive into their respective variables: x_train, y_train, x_test and y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5XTkRb0lqpEE"
      },
      "outputs": [],
      "source": [
        "# TODO (Students need to fill this section)\n",
        "# Loading the data from the files\n",
        "x_train = load('kmnist-train-imgs.npz')\n",
        "y_train = load('kmnist-train-labels.npz')\n",
        "x_test = load('kmnist-test-imgs.npz')\n",
        "y_test = load('kmnist-test-labels.npz')\n",
        "\n",
        "#Displaying the shapes of the loaded data\n",
        "print(\"The shape of X_train is:\", x_train.shape)\n",
        "print(\"The shape of y_train is:\", y_train.shape)\n",
        "print(\"The shape of X_test is:\", x_test.shape)\n",
        "print(\"The shape of y_test is:\", y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Oad71HZ7F9X"
      },
      "outputs": [],
      "source": [
        "#Unit testing\n",
        "import numpy as np\n",
        "\n",
        "# Flatten the images\n",
        "x_train_flattened = x_train.reshape(-1, 28*28)\n",
        "x_test_flattened = x_test.reshape(-1, 28*28)\n",
        "\n",
        "# Assert statements with modified shapes\n",
        "assert x_train_flattened.shape == (60000, 784)\n",
        "assert y_train.shape == (60000,)\n",
        "assert x_test_flattened.shape == (10000, 784)\n",
        "assert y_test.shape == (10000,)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KC12nB7rlbV"
      },
      "source": [
        "[3.5] **TODO** Using matplotlib display the first image from the train set and its target value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AOtWg7bBrwmV"
      },
      "outputs": [],
      "source": [
        "# TODO (Students need to fill this section)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Display the first image from the train set\n",
        "plt.imshow(x_train[0], cmap='gray')\n",
        "plt.title('First Image from Train Set')\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "# Display the target value for the first image\n",
        "print(\"Target value for the first image:\", y_train[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htLk_27ir0B1"
      },
      "source": [
        "# 4. Prepare Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJEBe30Er33P"
      },
      "source": [
        "[4.1] **TODO** Reshape the images from the training and testing set to have the channel dimension last. The dimensions should be: (row_number, height, width, channel)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1yqWleZasxdR"
      },
      "outputs": [],
      "source": [
        "# TODO (Students need to fill this section)\n",
        "img_height, img_width = 28, 28\n",
        "x_train = x_train.reshape(-1, img_height, img_width, 1)\n",
        "x_test = x_test.reshape(-1, img_height, img_width, 1)\n",
        "\n",
        "print(\"The reshape of x_train is:\", x_train.shape)\n",
        "print(\"The reshape of x_test is:\", x_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2f6wvFys2ZI"
      },
      "source": [
        "[4.2] **TODO** Cast `x_train` and `x_test` into `float32` decimals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FWZmWe73tLXT"
      },
      "outputs": [],
      "source": [
        "# TODO (Students need to fill this section)\n",
        "\n",
        "x_train_tensor = torch.tensor(x_train, dtype=torch.float32)\n",
        "x_test_tensor = torch.tensor(x_test, dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-1Jr0pKs6jv"
      },
      "source": [
        "[4.3] **TODO** Standardise the images of the training and testing sets. Originally each image contains pixels with value ranging from 0 to 255. after standardisation, the new value range should be from 0 to 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RXY1o272t0JO"
      },
      "outputs": [],
      "source": [
        "# TODO (Students need to fill this section)\n",
        "# Standardizing the images of the training and testing sets\n",
        "x_train = x_train_tensor / 255.0\n",
        "x_test = x_test_tensor / 255.0\n",
        "\n",
        "# Displaying the new value ranges\n",
        "print(\"New value range for x_train:\", x_train.min(), \"to\", x_train.max())\n",
        "print(\"New value range for x_test:\", x_test.min(), \"to\", x_test.max())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eH4aZmXt7Fe"
      },
      "source": [
        "[4.4] **TODO** Create a variable called `num_classes` that will take the value 10 which corresponds to the number of classes for the target variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gTnMgLxYuUs6"
      },
      "outputs": [],
      "source": [
        "# TODO (Students need to fill this section)\n",
        "num_classes = 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAy0fUJsuyhb"
      },
      "source": [
        "[4.5] **TODO** Convert the target variable for the training and testing sets to a binary class matrix of dimension (rows, num_classes).\n",
        "\n",
        "For example:\n",
        "- class 0 will become [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
        "- class 1 will become [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
        "- class 5 will become [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
        "- class 9 will become [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P09KGrQUOtmP"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "#Converting into numpy array\n",
        "y_train_ =  np.array(y_train, dtype=np.int64)\n",
        "y_test_ = np.array(y_test, dtype = np.int64)\n",
        "\n",
        "#Casting using torch.eye() function\n",
        "y_train = torch.eye(num_classes)[y_train_]\n",
        "y_test = torch.eye(num_classes)[y_test_]\n",
        "\n",
        "print(\"The shape of y_train is:\", y_train.shape)\n",
        "print(\"The shape of y_test is:\", y_test.shape)\n",
        "\n",
        "for i in range(10):\n",
        "  print(f\"Class {y_train_[i]}: {y_train[i]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OCorS00wxPN"
      },
      "source": [
        "# 5. Define Neural Networks Architecure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7G_L-yqTxI1d"
      },
      "source": [
        "[5.1] Set the seed in PyTorch for reproducing results\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XB8OIC9wrgFG"
      },
      "outputs": [],
      "source": [
        "# TODO (Students need to fill this section)\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMrH-XejqBlb"
      },
      "source": [
        "[5.2] TODO Define the architecture of your Neural Networks and save it into a variable called model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n4tI75i6p6lj"
      },
      "outputs": [],
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "# Recurrent Neural Networks (RNNs)\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(RNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(784, 128)  # Fully connected layer 1\n",
        "        self.relu = nn.ReLU()           # ReLU activation function\n",
        "        self.dropout = nn.Dropout(0.5)  # Dropout layer with dropout probability of 0.5\n",
        "        self.fc2 = nn.Linear(128, 10)   # Fully connected layer 2\n",
        "\n",
        "        self.tanh = nn.Tanh()     # Tanh activation function\n",
        "\n",
        "    def forward(self, x):\n",
        "      x = self.fc1(x)\n",
        "      x = self.relu(x)\n",
        "      x = self.dropout(x)\n",
        "      x = self.fc2(x)\n",
        "      x = self.tanh(x)\n",
        "      return x\n",
        "\n",
        "model = RNN()\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0IvuMQ81xu5U"
      },
      "source": [
        "[5.2] **TODO** Print the summary of your model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gBRm-h5dxvIw"
      },
      "outputs": [],
      "source": [
        "# TODO (Students need to fill this section)\n",
        "!python3.9 -m pip install torchsummary\n",
        "from torchsummary import summary\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "summary(model, input_size=(784,))\n",
        "\n",
        "# Defining the accuracy metric function\n",
        "def accuracy(outputs, labels):\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    correct = (predicted == labels).sum().item()\n",
        "    total = labels.size(0)\n",
        "    return correct / total\n",
        "\n",
        "# Assigning the accuracy metric function to the variable metric\n",
        "metric = accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOPTnNxtx6MC"
      },
      "source": [
        "# 6. Train Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsHJzhnAyP4H"
      },
      "source": [
        "[6.1] **TODO** Create 2 variables called `batch_size` and `epochs` that will  respectively take the values 128 and 500"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hNe_Cia0yde-"
      },
      "outputs": [],
      "source": [
        "# TODO (Students need to fill this section)\n",
        "batch_size = 128\n",
        "epochs = 500"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-bAkzwXyjAs"
      },
      "source": [
        "[6.2] **TODO** Compile your model with the appropriate loss function, the optimiser of your choice and the accuracy metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0WnNAYT6yjci"
      },
      "outputs": [],
      "source": [
        "# TODO (Students need to fill this section)\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Defining the accuracy metric function\n",
        "def accuracy(outputs, labels):\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    correct = (predicted == labels).sum().item()\n",
        "    total = labels.size(0)\n",
        "    return correct / total\n",
        "\n",
        "# Assigning the accuracy metric function to the variable metric\n",
        "metric = accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRvM_pEZy7SX"
      },
      "source": [
        "[6.3] **TODO** Train your model\n",
        "using the number of epochs defined. Calculate the total loss and save it to a variable called total_loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EUhflNHPdenZ"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Defining batch size and number of epochs\n",
        "BATCH_SIZE = 128\n",
        "epochs = 500\n",
        "train_losses = []  # To store training losses\n",
        "test_losses = []   # To store test losses\n",
        "train_accuracy = []  # To store training accuracy\n",
        "test_accuracy = []   # To store test accuracy\n",
        "\n",
        "\n",
        "train_loader = DataLoader(TensorDataset(x_train, y_train), batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = DataLoader(TensorDataset(x_test, y_test), batch_size=BATCH_SIZE)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()  # Setting the model to training mode\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for inputs, labels in train_loader:\n",
        "        optimizer.zero_grad()  # Zero the gradients\n",
        "        inputs = inputs.view(inputs.size(0), -1)  # Flattening the input data\n",
        "        outputs = model(inputs)  # Forward pass\n",
        "        loss = criterion(outputs, labels)  # Compute the loss\n",
        "        loss.backward()  # Backward pass\n",
        "        optimizer.step()  # Update weights\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == torch.argmax(labels, dim=1)).sum().item()\n",
        "\n",
        "    train_losses.append(running_loss/len(train_loader))  # Appending training loss\n",
        "    train_accuracy.append(correct / total)  # Appending training accuracy\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_losses[-1]:.4f}, Train Accuracy: {train_accuracy[-1]:.2%}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emZ5Ayr88PZh"
      },
      "source": [
        "[6.4] **TODO** Test your model.  Initiate the model.eval() along with torch.no_grad() to turn off the gradients.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3PRzKvBSfaNK"
      },
      "outputs": [],
      "source": [
        "# TODO (Students need to fill this section)\n",
        "test_losses = []   # To store test losses\n",
        "test_accuracy = []   # To store test accuracy\n",
        "model.eval()  # Set the model to evaluation mode\n",
        "correct = 0\n",
        "total = 0\n",
        "# Getting the predictions for the test dataset\n",
        "predicted_labels = []\n",
        "true_labels = []\n",
        "with torch.no_grad():  # Turning off gradients for evaluation\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs = inputs.view(inputs.size(0), -1)  # Flattening the input data\n",
        "        outputs = model(inputs)  # Forward pass\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == torch.argmax(labels, dim=1)).sum().item()\n",
        "\n",
        "        # Computing test loss (if needed)\n",
        "        test_loss = criterion(outputs, labels)\n",
        "        test_losses.append(test_loss.item())\n",
        "        predicted_labels.extend(predicted.tolist())\n",
        "        true_labels.extend(torch.argmax(labels, dim=1).tolist())\n",
        "# Computing test accuracy\n",
        "test_accuracy.append(correct / total)\n",
        "\n",
        "# Printing test results\n",
        "print(f\"Test Loss: {test_losses[-1]:.4f}, Test Accuracy: {test_accuracy[-1]:.2%}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vz9uFy_X6oeA"
      },
      "source": [
        "# 7. Analyse Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddugPZhZ68Wb"
      },
      "source": [
        "[7.1] **TODO** Display the performance of your model on the training and testing sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yihZIPZ_6sql"
      },
      "outputs": [],
      "source": [
        "# TODO (Students need to fill this section)\n",
        "plt.plot(train_losses, label='Training Loss')\n",
        "plt.plot(test_losses, label='Testing Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Testing Losses')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBTo_xEI7K_z"
      },
      "source": [
        "[7.2] **TODO** Plot the learning curve of your model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jRt_4W2F7RVV"
      },
      "outputs": [],
      "source": [
        "# TODO (Students need to fill this section)\n",
        "plt.plot(range(1, epochs+1), train_accuracy, label='Training Accuracy')\n",
        "plt.plot(range(1, epochs+1), [test_accuracy[-1]] * epochs, label='Test Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training and Test Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKPu98GR7a17"
      },
      "source": [
        "[7.3] **TODO** Display the confusion matrix on the testing set predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TkrP9JCgMzpT"
      },
      "outputs": [],
      "source": [
        "# TODO (Students need to fill this section)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Computing the confusion matrix\n",
        "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
        "\n",
        "# Plotting the confusion matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "plt.xlabel('Predicted labels')\n",
        "plt.ylabel('True labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-t5N8ONkqoAv"
      },
      "source": [
        "# Model 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jk9TNNHIqnFS"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the model\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(RNN, self).__init__()\n",
        "        self.flatten = nn.Flatten()  # Flatten layer to convert 2D images to 1D vectors\n",
        "        self.fc1 = nn.Linear(784, 256)  # Input layer (784 inputs, 256 outputs)\n",
        "        self.fc2 = nn.Linear(256, 128)  # Hidden layer 1 (256 inputs, 128 outputs)\n",
        "        self.fc3 = nn.Linear(128, 64)   # Hidden layer 2 (128 inputs, 64 outputs)\n",
        "        self.fc4 = nn.Linear(64, 10)    # Hidden layer 3 (64 inputs, 32 outputs)\n",
        "        self.relu = nn.ReLU()           # ReLU activation function\n",
        "        self.dropout = nn.Dropout(0.5)  # Dropout layer with dropout probability of 0.5\n",
        "        self.tanh = nn.Tanh()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)  # Flattening the input images\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc3(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc4(x)\n",
        "        x = self.tanh(x)\n",
        "        return x\n",
        "\n",
        "# Print the model architecture\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7oOu_DlRqw0s"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.002)\n",
        "\n",
        "# Defining the accuracy metric function\n",
        "def accuracy(outputs, labels):\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    correct = (predicted == labels).sum().item()\n",
        "    total = labels.size(0)\n",
        "    return correct / total\n",
        "\n",
        "# Assigning the accuracy metric function to the variable metric\n",
        "metric = accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nlf-vQxYoLt6"
      },
      "outputs": [],
      "source": [
        "# TODO (Students need to fill this section)\n",
        "#!python3.9 -m pip install torchsummary\n",
        "from torchsummary import summary\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "summary(model, input_size=(784,))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQiOIllaoLt6"
      },
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M5BT1Cuoq1ak"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define batch size and number of epochs\n",
        "BATCH_SIZE = 128\n",
        "epochs = 50\n",
        "train_losses = []  # To store training losses\n",
        "test_losses = []   # To store test losses\n",
        "train_accuracy = []  # To store training accuracy\n",
        "test_accuracy = []   # To store test accuracy\n",
        "\n",
        "\n",
        "train_loader = DataLoader(TensorDataset(x_train, y_train), batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = DataLoader(TensorDataset(x_test, y_test), batch_size=BATCH_SIZE)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()  # Setting the model to training mode\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for inputs, labels in train_loader:\n",
        "        optimizer.zero_grad()  # Zero the gradients\n",
        "        inputs = inputs.view(inputs.size(0), -1)  # Flatten the input data\n",
        "        outputs = model(inputs)  # Forward pass\n",
        "        loss = criterion(outputs, labels)  # Compute the loss\n",
        "        loss.backward()  # Backward pass\n",
        "        optimizer.step()  # Update weights\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == torch.argmax(labels, dim=1)).sum().item()\n",
        "\n",
        "    train_losses.append(running_loss/len(train_loader))  # Appending training loss\n",
        "    train_accuracy.append(correct / total)  # Appending training accuracy\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_losses[-1]:.4f}, Train Accuracy: {train_accuracy[-1]:.2%}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05ln7botoLt7"
      },
      "source": [
        "## Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L78j6bwuq7fQ"
      },
      "outputs": [],
      "source": [
        "# TODO (Students need to fill this section)\n",
        "test_losses = []   # To store test losses\n",
        "test_accuracy = []   # To store test accuracy\n",
        "model.eval()  # Set the model to evaluation mode\n",
        "correct = 0\n",
        "total = 0\n",
        "# Getting the predictions for the test dataset\n",
        "predicted_labels = []\n",
        "true_labels = []\n",
        "with torch.no_grad():  # Turn off gradients for evaluation\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs = inputs.view(inputs.size(0), -1)  # Flatten the input data\n",
        "        outputs = model(inputs)  # Forward pass\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == torch.argmax(labels, dim=1)).sum().item()\n",
        "\n",
        "        # Computing test loss (if needed)\n",
        "        test_loss = criterion(outputs, labels)\n",
        "        test_losses.append(test_loss.item())\n",
        "        predicted_labels.extend(predicted.tolist())\n",
        "        true_labels.extend(torch.argmax(labels, dim=1).tolist())\n",
        "# Computing test accuracy\n",
        "test_accuracy.append(correct / total)\n",
        "\n",
        "# Printing test results\n",
        "print(f\"Epoch [{epoch+1}/{epochs}], Test Loss: {test_losses[-1]:.4f}, Test Accuracy: {test_accuracy[-1]:.2%}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALpU8rI7oLt7"
      },
      "source": [
        "## Performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nKGYsTUnoLt7"
      },
      "outputs": [],
      "source": [
        "# TODO (Students need to fill this section)\n",
        "plt.plot(train_losses, label='Training Loss')\n",
        "plt.plot(test_losses, label='Testing Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Testing Losses')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nG_dVduUx-Je"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Plotting\n",
        "plt.plot(range(1, epochs+1), train_accuracy, label='Training Accuracy')\n",
        "plt.plot(range(1, epochs+1), [test_accuracy[-1]] * epochs, label='Test Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training and Test Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TU4eABuAoLt7"
      },
      "source": [
        "## Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oBzc0Gl1A0Qh"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Computing the confusion matrix\n",
        "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
        "\n",
        "# Plotting the confusion matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "plt.xlabel('Predicted labels')\n",
        "plt.ylabel('True labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FuTuTCizIhG"
      },
      "source": [
        "# Model 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pr4YJEgIoLt7"
      },
      "source": [
        "## Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5lWuereARUx-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "# Recurrent Neural Networks (RNNs)\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(RNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(784, 128)  # Fully connected layer 1\n",
        "        self.relu = nn.ReLU()           # ReLU activation function\n",
        "        self.dropout = nn.Dropout(0.5)  # Dropout layer with dropout probability of 0.5\n",
        "        self.fc2 = nn.Linear(128, 64)   # Fully connected layer 2\n",
        "        self.fc3 = nn.Linear(64, 32)    # Fully connected layer 3\n",
        "        self.fc4 = nn.Linear(32, 10)    # Fully connected layer 4\n",
        "        self.tanh = nn.Tanh()     # Tanh activation function\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc3(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc4(x)\n",
        "        x = self.tanh(x)\n",
        "        return x\n",
        "\n",
        "model = RNN()\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17P__GsDoLt8"
      },
      "source": [
        "## Loss Function and Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eJllAx22zm4J"
      },
      "outputs": [],
      "source": [
        "# Defining the loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Defining the optimizer with L2 regularization\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.001)\n",
        "\n",
        "# Defining the accuracy metric function\n",
        "def accuracy(outputs, labels):\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    correct = (predicted == labels).sum().item()\n",
        "    total = labels.size(0)\n",
        "    return correct / total\n",
        "\n",
        "# Assigning the accuracy metric function to the variable metric\n",
        "metric = accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDzhDQ4aoLt8"
      },
      "source": [
        "## Model Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-N3pddDioLt8"
      },
      "outputs": [],
      "source": [
        "# TODO (Students need to fill this section)\n",
        "#!python3.9 -m pip install torchsummary\n",
        "from torchsummary import summary\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "summary(model, input_size=(784,))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFsJzgOkoLt8"
      },
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "78ABu0Na0hZs"
      },
      "outputs": [],
      "source": [
        "# Defining batch size and number of epochs\n",
        "BATCH_SIZE = 128\n",
        "epochs = 20\n",
        "train_losses = []  # To store training losses\n",
        "train_accuracy = []  # To store training accuracy\n",
        "losses = []\n",
        "\n",
        "\n",
        "train_loader = DataLoader(TensorDataset(x_train, y_train), batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = DataLoader(TensorDataset(x_test, y_test), batch_size=BATCH_SIZE)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()  # Setting the model to training mode\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for inputs, labels in train_loader:\n",
        "        optimizer.zero_grad()  # Zero the gradients\n",
        "        inputs = inputs.view(inputs.size(0), -1)  # Flatten the input data\n",
        "        outputs = model(inputs)  # Forward pass\n",
        "        loss = criterion(outputs, labels)  # Compute the loss\n",
        "        loss.backward()  # Backward pass\n",
        "        optimizer.step()  # Update weights\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == torch.argmax(labels, dim=1)).sum().item()\n",
        "\n",
        "    train_losses.append(running_loss/len(train_loader))  # Appending training loss\n",
        "    train_accuracy.append(correct / total)  # Appending training accuracy\n",
        "\n",
        "    # Printing training results\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_losses[-1]:.4f}, Train Accuracy: {train_accuracy[-1]:.2%}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdL9mKePoLt8"
      },
      "source": [
        "## Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lb0NtrTN4GRg"
      },
      "outputs": [],
      "source": [
        "# Testing loop\n",
        "test_losses = []   # To store test losses\n",
        "test_accuracy = []   # To store test accuracy\n",
        "model.eval()  # Set the model to evaluation mode\n",
        "correct = 0\n",
        "total = 0\n",
        "# Getting the predictions for the test dataset\n",
        "predicted_labels = []\n",
        "true_labels = []\n",
        "with torch.no_grad():  # Turnning off gradients for evaluation\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs = inputs.view(inputs.size(0), -1)  # Flattening the input data\n",
        "        outputs = model(inputs)  # Forward pass\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == torch.argmax(labels, dim=1)).sum().item()\n",
        "\n",
        "        # Computing test loss (if needed)\n",
        "        test_loss = criterion(outputs, labels)\n",
        "        test_losses.append(test_loss.item())\n",
        "        predicted_labels.extend(predicted.tolist())\n",
        "        true_labels.extend(torch.argmax(labels, dim=1).tolist())\n",
        "# Computing test accuracy\n",
        "test_accuracy.append(correct / total)\n",
        "\n",
        "# Printing test results\n",
        "print(f\"Test Loss: {test_losses[-1]:.4f}, Test Accuracy: {test_accuracy[-1]:.2%}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYAW_k6d91dG"
      },
      "source": [
        "# Graphical representation of Performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gMdt_ta7oLt9"
      },
      "outputs": [],
      "source": [
        "# Solution\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# TODO (Students need to fill this section)\n",
        "plt.plot(train_losses, label='Training Loss')\n",
        "plt.plot(test_losses, label='Testing Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Testing Losses')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OxYGgUe5_zFZ"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Plotting\n",
        "plt.plot(range(1, epochs+1), train_accuracy, label='Training Accuracy')\n",
        "plt.plot(range(1, epochs+1), [test_accuracy[-1]] * epochs, label='Test Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training and Test Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwfJMhMz9yen"
      },
      "source": [
        "# Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dD4N4Xa54Ted"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Computting the confusion matrix\n",
        "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
        "\n",
        "# Plotting the confusion matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "plt.xlabel('Predicted labels')\n",
        "plt.ylabel('True labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6pmggROoLt9"
      },
      "source": [
        "# Module 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOrCgmGXoLt9"
      },
      "source": [
        "## Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jBKWJ_hIoLt9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "# Recurrent Neural Networks (RNNs)\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(RNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(784, 256)  # Input layer (784 inputs, 256 outputs)\n",
        "        self.fc2 = nn.Linear(256, 128)  # Hidden layer 1 (256 inputs, 128 outputs)\n",
        "        self.fc3 = nn.Linear(128, 64)   # Hidden layer 2 (128 inputs, 64 outputs)\n",
        "        self.fc4 = nn.Linear(64, 32)    # Hidden layer 3 (64 inputs, 32 outputs)\n",
        "        self.fc5 = nn.Linear(32, 10)     # Output layer (32 inputs, 1 output)\n",
        "        self.relu = nn.ReLU()           # ReLU activation function\n",
        "        self.dropout = nn.Dropout(p=0.5)  # Dropout layer with 50% probability\n",
        "        self.softmax = nn.Softmax()     # softmax activation function for binary classification\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 784)             # Flatten the input tensor\n",
        "        x = self.relu(self.fc1(x))      # Pass through first linear layer and apply ReLU activation\n",
        "        x = self.dropout(x)             # Apply dropout\n",
        "        x = self.relu(self.fc2(x))      # Pass through second linear layer and apply ReLU activation\n",
        "        x = self.dropout(x)             # Apply dropout\n",
        "        x = self.relu(self.fc3(x))      # Pass through third linear layer and apply ReLU activation\n",
        "        x = self.dropout(x)             # Apply dropout\n",
        "        x = self.relu(self.fc4(x))      # Pass through fourth linear layer and apply ReLU activation\n",
        "        x = self.dropout(x)             # Apply dropout\n",
        "        x = self.fc5(x)                 # Pass through fifth linear layer\n",
        "        x = self.softmax(x)             # Apply softmax activation for binary classification\n",
        "        return x\n",
        "\n",
        "# Instantiating the model\n",
        "model = RNN()\n",
        "print(model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_puodIpoLt9"
      },
      "source": [
        "## Loss Function and Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VPmXW1k1oLt9"
      },
      "outputs": [],
      "source": [
        "# Defining the loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Defining the optimizer with L2 regularization\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
        "\n",
        "# Defining the accuracy metric function\n",
        "def accuracy(outputs, labels):\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    correct = (predicted == labels).sum().item()\n",
        "    total = labels.size(0)\n",
        "    return correct / total\n",
        "\n",
        "# Assigning the accuracy metric function to the variable metric\n",
        "metric = accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCixcFjyoLt9"
      },
      "source": [
        "## Model Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e1qveNssoLt9"
      },
      "outputs": [],
      "source": [
        "# TODO (Students need to fill this section)\n",
        "!python3.9 -m pip install torchsummary\n",
        "from torchsummary import summary\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "summary(model, input_size=(784,))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2nunVHGoLt9"
      },
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cpGz7LJWoLt9"
      },
      "outputs": [],
      "source": [
        "# Defining batch size and number of epochs\n",
        "BATCH_SIZE = 128\n",
        "epochs = 100\n",
        "train_losses = []  # To store training losses\n",
        "train_accuracy = []  # To store training accuracy\n",
        "losses = []\n",
        "\n",
        "\n",
        "train_loader = DataLoader(TensorDataset(x_train, y_train), batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = DataLoader(TensorDataset(x_test, y_test), batch_size=BATCH_SIZE)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()  # Setting the model to training mode\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for inputs, labels in train_loader:\n",
        "        optimizer.zero_grad()  # Zero the gradients\n",
        "        inputs = inputs.view(inputs.size(0), -1)  # Flatten the input data\n",
        "        outputs = model(inputs)  # Forward pass\n",
        "        loss = criterion(outputs, labels)  # Compute the loss\n",
        "        loss.backward()  # Backward pass\n",
        "        optimizer.step()  # Update weights\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == torch.argmax(labels, dim=1)).sum().item()\n",
        "\n",
        "    train_losses.append(running_loss/len(train_loader))  # Appending training loss\n",
        "    train_accuracy.append(correct / total)  # Appending training accuracy\n",
        "\n",
        "    # Printing training results\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_losses[-1]:.4f}, Train Accuracy: {train_accuracy[-1]:.2%}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6nIXj7PoLt-"
      },
      "source": [
        "## Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ai3UCliGoLt-"
      },
      "outputs": [],
      "source": [
        "# Testing loop\n",
        "test_losses = []   # To store test losses\n",
        "test_accuracy = []   # To store test accuracy\n",
        "model.eval()  # Setting the model to evaluation mode\n",
        "correct = 0\n",
        "total = 0\n",
        "# Getting the predictions for the test dataset\n",
        "predicted_labels = []\n",
        "true_labels = []\n",
        "with torch.no_grad():  # Turning off gradients for evaluation\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs = inputs.view(inputs.size(0), -1)  # Flatten the input data\n",
        "        outputs = model(inputs)  # Forward pass\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == torch.argmax(labels, dim=1)).sum().item()\n",
        "\n",
        "        # Computing test loss (if needed)\n",
        "        test_loss = criterion(outputs, labels)\n",
        "        test_losses.append(test_loss.item())\n",
        "        predicted_labels.extend(predicted.tolist())\n",
        "        true_labels.extend(torch.argmax(labels, dim=1).tolist())\n",
        "# Computing test accuracy\n",
        "test_accuracy.append(correct / total)\n",
        "\n",
        "# Printing test results\n",
        "print(f\"Test Loss: {test_losses[-1]:.4f}, Test Accuracy: {test_accuracy[-1]:.2%}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzPLvmY2oLt-"
      },
      "source": [
        "## Loss Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IF-2Gg5QoLt-"
      },
      "outputs": [],
      "source": [
        "# Solution\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# TODO (Students need to fill this section)\n",
        "plt.plot(train_losses, label='Training Loss')\n",
        "plt.plot(test_losses, label='Testing Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Testing Losses')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZEpG8jikoLt-"
      },
      "source": [
        "## Model Performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RZep0qZ2oLt-"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Plotting\n",
        "plt.plot(range(1, epochs+1), train_accuracy, label='Training Accuracy')\n",
        "plt.plot(range(1, epochs+1), [test_accuracy[-1]] * epochs, label='Test Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training and Test Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFQcVw70oLt-"
      },
      "source": [
        "## Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YsyCpMsXoLt-"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Computing the confusion matrix\n",
        "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
        "\n",
        "# Plotting the confusion matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "plt.xlabel('Predicted labels')\n",
        "plt.ylabel('True labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}